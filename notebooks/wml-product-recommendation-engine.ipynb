{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a product recommendation engine\n",
    "\n",
    "![](https://raw.githubusercontent.com/IBM/product-recommendation-with-watson-ml/master/doc/source/images/shopping.png)\n",
    "\n",
    "This notebook contains steps and code to create a recommendation engine based on shopping history and deploy that model to Watson Machine Learning. This notebook runs on Python 3.x with Apache Spark 2.3.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "The learning goals of this notebook are:\n",
    "\n",
    "* Load a CSV file into the Object Storage service linked to your Watson Studio\n",
    "* Use the *k*-means algorithm, which is useful for cluster analysis in data mining, to segment customers into clusters for the purpose of making an in-store purchase recommendation\n",
    "* Deploy the model to the IBM Watson Machine Learning service in IBM Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Setup](#setup)<br>\n",
    "2. [Load and explore data](#load)<br>\n",
    "3. [Create a KMeans model](#kmeans)<br>\n",
    "   3.1. [Prepare data](#prepare_data)<br>\n",
    "   3.2. [Create clusters and define the model](#build_model)<br>\n",
    "4. [Persist the model](#persist)<br>\n",
    "5. [Deploy the model to the cloud](#deploy)<br>\n",
    "   5.1. [Create deployment for the model](#create_deploy)<br>\n",
    "   5.2. [Test model deployment](#test_deploy)<br>\n",
    "6. [Create product recommendations](#create_recomm)<br>\n",
    "   6.1. [Test product recommendations model](#test_recomm)<br>\n",
    "7. [Summary and next steps](#summary)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "* Create a Watson Machine Learning service instance (a free plan is offered) and associate it with your project\n",
    "* Create a Cloud Object Storage service instance (a free plan is offered) and associate it with your project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using a couple libraries for this exercise:\n",
    "\n",
    "1. [Watson Machine Learning Client](http://wml-api-pyclient.mybluemix.net/): Client library to work with the Watson Machine Learning service on IBM Cloud. Library available on [pypi](https://pypi.org/project/watson-machine-learning-client/). Service available on [IBM Cloud](https://cloud.ibm.com/catalog/services/machine-learning).\n",
    "1. [ibmos2spark](https://github.com/ibm-watson-data-lab/ibmos2spark): Facilitates Data I/O between Spark and IBM Object Storage services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade ibmos2spark\n",
    "!pip install --upgrade watson-machine-learning-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "## 2. Load and explore data\n",
    "\n",
    "In this section you will load and access the data file that contains the customer shopping data using [Cloud Object Storage in the notebook](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/load-and-access-data.html):\n",
    "\n",
    "1. Place cursor into the next cell (`# Generated Code Here`)\n",
    "1. Click the **Find and Add Data** icon to open the Files and Connections side bar\n",
    "1. Click **browse** and navigate to and select the `customers_orders1_opt.csv`\n",
    "1. Click **Insert to code**\n",
    "1. Select **SparkSession DataFrame**\n",
    "\n",
    "Code to download and import the CSV data into a Spark DataFrame is generated and added into the notebook cell.\n",
    "\n",
    "```\n",
    "import ibmos2spark\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'endpoint': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'service_id': '***',\n",
    "    'iam_service_endpoint': 'https://iam.ng.bluemix.net/oidc/token',\n",
    "    'api_key': '***'\n",
    "}\n",
    "\n",
    "configuration_name = 'os_7135ade4b1d24e67b69b610d4a20966c_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df_data_1 = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .load(cos.url('customers_orders1_opt.csv', '***'))\n",
    "df_data_1.take(5)\n",
    "```\n",
    "\n",
    "Run the generated code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Update and set the `df` variable to the dataframe variable (e.g., `df_data_1`) created by the generated code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"kmeans\"></a>\n",
    "## 3. Create a *k*-means model with Spark\n",
    "\n",
    "In this section of the notebook you use the *k*-means implementation to associate every customer to a cluster based on their shopping history.\n",
    "\n",
    "First, import the Apache Spark Machine Learning packages ([MLlib](http://spark.apache.org/docs/2.2.0/api/python/pyspark.ml.html)) that you need in the subsequent steps:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.clustering import KMeansModel\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepare_data\"></a>\n",
    "### 3.1 Prepare data\n",
    "\n",
    "Create a new data set with just the data that you need. Filter the columns that you want, in this case the customer ID column and the product-related columns. Remove the columns that you don't need for aggregating the data and training the model. Convert the column types from `StringType` to `IntegerType`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Here are the product cols. In a real world scenario we would query a product table, or similar.\n",
    "product_cols = ['Baby Food', 'Diapers', 'Formula', 'Lotion', 'Baby wash', 'Wipes', 'Fresh Fruits', 'Fresh Vegetables', 'Beer', 'Wine', 'Club Soda', 'Sports Drink', 'Chips', 'Popcorn', 'Oatmeal', 'Medicines', 'Canned Foods', 'Cigarettes', 'Cheese', 'Cleaning Products', 'Condiments', 'Frozen Foods', 'Kitchen Items', 'Meat', 'Office Supplies', 'Personal Care', 'Pet Supplies', 'Sea Food', 'Spices']\n",
    "# Here we get the customer ID and the products they purchased\n",
    "df_filtered = df.select(['CUST_ID'] + product_cols)\n",
    "\n",
    "for c in product_cols:\n",
    "    df_filtered = df_filtered.withColumn(c, df[c].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "View the filtered information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, aggregate the individual transactions for each customer to get a single score per product, per customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_products = df_filtered.groupby('CUST_ID').sum()  # Use customer IDs to group transactions by customer and sum them up\n",
    "df_customer_products = df_customer_products.drop('sum(CUST_ID)')\n",
    "\n",
    "df_customer_products.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build_model\"></a>\n",
    "### 3.2 Create clusters and define the model \n",
    "\n",
    "Create 100 clusters with a *k*-means model based on the number of times a specific customer purchased a product.\n",
    "\n",
    "| No Clustering | Clustering |\n",
    "|------|------|\n",
    "|  ![](https://raw.githubusercontent.com/IBM/product-recommendation-with-watson-ml/master/doc/source/images/kmeans-1.jpg)  | ![](https://raw.githubusercontent.com/IBM/product-recommendation-with-watson-ml/master/doc/source/images/kmeans-2.jpg) |\n",
    "\n",
    "First, create a feature vector by combining the product and quantity columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"sum({})\".format(x) for x in product_cols],outputCol=\"features\") # Assemble vectors using product fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the *k*-means clusters and the pipeline to define the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(maxIter=50, predictionCol=\"cluster\").setK(100).setSeed(1)  # Initialize model\n",
    "pipeline = Pipeline(stages=[assembler, kmeans])\n",
    "model = pipeline.fit(df_customer_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, calculate the cluster for each customer by running the original dataset against the *k*-means model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_customer_products_cluster = model.transform(df_customer_products)\n",
    "df_customer_products_cluster.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"persist\"></a>\n",
    "## 4. Persist the model \n",
    "\n",
    "In this section you will learn how to store your pipeline and model in Watson Machine Learning repository by using Python client libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Configure IBM Watson Machine Learning credentials\n",
    "\n",
    "To access your machine learning repository programmatically, you need to copy in your credentials, which you can see in your **IBM Watson Machine Learning** service details in IBM Cloud.\n",
    "\n",
    "> **IMPORTANT**: Update `apikey` and `instance_id` below. Credentials can be found on _Service Credentials_ tab of the Watson Machine Learning service instance created on the IBM Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "wml_credentials = {\n",
    "  \"apikey\": \"***\",\n",
    "  \"iam_apikey_description\": \"Auto-generated for key ***\",\n",
    "  \"iam_apikey_name\": \"Service credentials-1\",\n",
    "  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n",
    "  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/***\",\n",
    "  \"instance_id\": \"***\",\n",
    "  \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "}\n",
    "\n",
    "print(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the Watson Machine Learning service using the provided credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "client = WatsonMachineLearningAPIClient(wml_credentials)\n",
    "print(client.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Save the model \n",
    "\n",
    "#### Save the model to the Watson Machine Learning repository\n",
    "\n",
    "You use the Watson Machine Learning client's [Repository class](http://wml-api-pyclient.mybluemix.net/#repository) to store and manage models in the Watson Machine Learning service. \n",
    "\n",
    "> **NOTE**: You can also use Watson Studio to manage models. In this notebook we are using the client library instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df_customer_products.withColumnRenamed('CUST_ID', 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **TIP**: Update the cell below with your name, email, and name you wish to give to your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_props = {client.repository.ModelMetaNames.AUTHOR_NAME: \"IBM\", \n",
    "               client.repository.ModelMetaNames.NAME: \"Shopping Recommendation Engine\"}\n",
    "published_model = client.repository.store_model(model=model, pipeline=pipeline, meta_props=model_props, training_data=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE**: You can delete a model from the repository by calling `client.repository.delete`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display list of existing models in the Watson Machine Learning repository "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.repository.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display information about the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "saved_model_uid = client.repository.get_model_uid(published_model)\n",
    "model_details = client.repository.get_details(saved_model_uid)\n",
    "print(json.dumps(model_details, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deploy\"></a>\n",
    "## 5. Deploy model to the IBM cloud\n",
    "\n",
    "You use the Watson Machine Learning client's [Deployments class](http://wml-api-pyclient.mybluemix.net/#deployments) to deploy and score models.\n",
    "\n",
    "### 5.1 Create an online deployment for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_deployment = client.deployments.create(saved_model_uid, 'Shopping Recommendation Engine Deployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Retrieve the scoring endpoint for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_endpoint = client.deployments.get_scoring_url(created_deployment)\n",
    "print(scoring_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test_deploy\"></a>\n",
    "### 5.3 Test the deployed model\n",
    "\n",
    "To verify that the model was successfully deployed to the cloud, you'll specify a customer ID, for example customer 12027, to predict this customer's cluster against the Watson Machine Learning deployment, and see if it matches the cluster that was previously associated this customer ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = df_customer_products_cluster.filter('CUST_ID = 12027').collect()\n",
    "print(\"Previously calculated cluster = {}\".format(customer[0].cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the customer's cluster using Watson Machine Learning, you need to load the customer's purchase history. This function uses the local data frame to select every product field and the number of times that customer 12027 purchased a product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six import iteritems\n",
    "def get_product_counts_for_customer(cust_id):\n",
    "    cust = df_customer_products.filter('CUST_ID = {}'.format(cust_id)).take(1)\n",
    "    fields = []\n",
    "    values = []\n",
    "    for row in cust:\n",
    "        for product_col in product_cols:\n",
    "            field = 'sum({})'.format(product_col)\n",
    "            value = row[field]\n",
    "            fields.append(field)\n",
    "            values.append(value)\n",
    "    return (fields, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes the customer's purchase history and calls the scoring endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_from_watson_ml(fields, values):\n",
    "    scoring_payload = {'fields': fields, 'values': [values]}\n",
    "    predictions = client.deployments.score(scoring_endpoint, scoring_payload)   \n",
    "    return predictions['values'][0][len(product_cols)+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, call the functions defined above to get the product history, call the scoring endpoint, and get the cluster associated to customer 12027:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_counts = get_product_counts_for_customer(12027)\n",
    "fields = product_counts[0]\n",
    "values = product_counts[1]\n",
    "print(\"Cluster calculated by Watson ML = {}\".format(get_cluster_from_watson_ml(fields, values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_recomm\"></a>\n",
    "## 6. Create product recommendations\n",
    "\n",
    "Now you can create some product recommendations.\n",
    "\n",
    "First, run this cell to create a function that queries the database and finds the most popular items for a cluster. In this case, the **df_customer_products_cluster** dataframe is the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gets the most popular clusters in the cell by grouping by the cluster column\n",
    "def get_popular_products_in_cluster(cluster):\n",
    "    df_cluster_products = df_customer_products_cluster.filter('cluster = {}'.format(cluster))\n",
    "    df_cluster_products_agg = df_cluster_products.groupby('cluster').sum()\n",
    "    row = df_cluster_products_agg.rdd.collect()[0]\n",
    "    items = []\n",
    "    for product_col in product_cols:\n",
    "        field = 'sum(sum({}))'.format(product_col)\n",
    "        items.append((product_col, row[field]))\n",
    "    sortedItems = sorted(items, key=lambda x: x[1], reverse=True) # Sort by score\n",
    "    popular = [x for x in sortedItems if x[1] > 0]\n",
    "    return popular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run this cell to create a function that will calculate the recommendations based on a given cluster. This function finds the most popular products in the cluster, filters out products already purchased by the customer or currently in the customer's shopping cart, and finally produces a list of recommended products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes a cluster and the quantity of every product already purchased or in the user's cart\n",
    "from pyspark.sql.functions import desc\n",
    "def get_recommendations_by_cluster(cluster, purchased_quantities):\n",
    "    # Existing customer products\n",
    "    print('PRODUCTS ALREADY PURCHASED/IN CART:')\n",
    "    customer_products = []\n",
    "    for i in range(0, len(product_cols)):\n",
    "        if purchased_quantities[i] > 0:\n",
    "            customer_products.append((product_cols[i], purchased_quantities[i]))\n",
    "    df_customer_products = sc.parallelize(customer_products).toDF([\"PRODUCT\",\"COUNT\"])\n",
    "    df_customer_products.show()\n",
    "    # Get popular products in the cluster\n",
    "    print('POPULAR PRODUCTS IN CLUSTER:')\n",
    "    cluster_products = get_popular_products_in_cluster(cluster)\n",
    "    df_cluster_products = sc.parallelize(cluster_products).toDF([\"PRODUCT\",\"COUNT\"])\n",
    "    df_cluster_products.show()\n",
    "    # Filter out products the user has already purchased\n",
    "    print('RECOMMENDED PRODUCTS:')\n",
    "    df_recommended_products = df_cluster_products.alias('cl').join(df_customer_products.alias('cu'), df_cluster_products['PRODUCT'] == df_customer_products['PRODUCT'], 'leftouter')\n",
    "    df_recommended_products = df_recommended_products.filter('cu.PRODUCT IS NULL').select('cl.PRODUCT','cl.COUNT').sort(desc('cl.COUNT'))\n",
    "    df_recommended_products.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run this cell to create a function that produces a list of recommended items based on the products and quantities in a user's cart. This function uses Watson Machine Learning to calculate the cluster based on the shopping cart contents and then calls the **get_recommendations_by_cluster** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function would be used to find recommendations based on the products and quantities in a user's cart\n",
    "def get_recommendations_for_shopping_cart(products, quantities):\n",
    "    fields = []\n",
    "    values = []\n",
    "    for product_col in product_cols:\n",
    "        field = 'sum({})'.format(product_col)\n",
    "        if product_col in products:\n",
    "            value = quantities[products.index(product_col)]\n",
    "        else:\n",
    "            value = 0\n",
    "        fields.append(field)\n",
    "        values.append(value)\n",
    "    return get_recommendations_by_cluster(get_cluster_from_watson_ml(fields, values), values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell to create a function that produces a list of recommended items based on the purchase history of a customer. This function uses Watson Machine Learning to calculate the cluster based on the customer's purchase history and then calls the **get_recommendations_by_cluster** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to find recommendations based on the purchase history of a customer\n",
    "def get_recommendations_for_customer_purchase_history(customer_id):\n",
    "    product_counts = get_product_counts_for_customer(customer_id)\n",
    "    fields = product_counts[0]\n",
    "    values = product_counts[1]\n",
    "    return get_recommendations_by_cluster(get_cluster_from_watson_ml(fields, values), values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can take customer 12027 and produce a recommendation based on that customer's purchase history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_for_customer_purchase_history(12027)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, take a sample shopping cart and produce a recommendation based on the items in the cart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_for_shopping_cart(['Diapers','Baby wash','Oatmeal'],[1,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=green>Congratulations</font>, you've sucessfully created a recommendation engine and deployed it to the Watson Machine Learning service\n",
    "\n",
    "You can now switch to the Watson Machine Learning console to deploy the model and then test it in application, or continue within the notebook to deploy the model using the APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 with Spark",
   "language": "python3",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
